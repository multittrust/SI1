<div class="container" id="topics">
  <div class="container">
    <div class="row me-row content-ct">
      <h2 class="row-title">Topics of Interest</h2>
      <div class="col-md feature">
        <h3>Trust Development and Measurement</h3>
        <p>This topic focuses on the quantification and analysis of trust within and between human-AI interactions. Suggested research areas include:</p>
        <ul>
          <li>Computational methods for estimating trust and/or trustworthiness.</li>
          <li>Evolution of trust over time and across team development stages and timescales.</li>
          <li>Relationship between measures of trust and human-AI teaming performance.</li>
          <li>Team-level and individual-level models of trust development and measurement.</li>
        </ul>
        
        <h3>Psychology and Dynamics of Human-AI Interaction</h3>
        <p>This section addresses the interplay between human cognitive processes and AI behavior. It aims to uncover the psychological foundations that underpin human interactions with AI and how these interactions influence team collaboration and trust. Potential research directions encompass:</p>
        <ul>
          <li>Integrative models of trust, team cognitive processes, and team outputs.</li>
          <li>Impacts of AI linguistic and prosocial capabilities on trust and trust-related perceptions.</li>
          <li>Psychological impact of AI failures on trust.</li>
          <li>Impact of trust in collaboration.</li>
        </ul>
      
        <h3>Transparency, Communication, and AI System Design</h3>
        <p>This part investigates the role of transparency in AI systems. The focus is on how the design and communication strategies of AI impact its perception as a trustworthy agent within sociotechnical environments. Recommended topics for investigation are:</p>
        <ul>
          <li>Role of AI transparency and explainability in influencing trustworthiness perception and collaboration.</li>
          <li>Design and implementation of trustworthy AI systems with a focus on transparent communication.</li>
          <li>Efficacy of transparency designs and interventions on trust and human-AI team outcomes.</li>
        </ul>
      
        <h3>Ethics, Bias, and Trust</h3>
        <p>This section considers how biases in AI, whether from data or algorithm design, affect trust, and explores strategies to mitigate such biases. The section also focuses on the role of ethical AI development in fostering trust. Possible directions include:</p>
        <ul>
          <li>Distinguishing between AI trustworthiness and human trust in AI.</li>
          <li>Investigations of AI biases' effects on user trust and strategies for reducing bias to build trust.</li>
          <li>Ethical AI design and deployment, focusing on issues of fairness and transparency across sectors.</li>
        </ul>
      
        <h3>Multidisciplinary Landscape</h3>
        <p>These themes collectively aim to provide a comprehensive understanding of trust in human-AI teams from various disciplinary perspectives. This deliberate choice ensures a broad range of techniques and applications can be discussed, encouraging submissions that explore trust across diverse AI interfaces and methodologies.</p>
      </div>
    </div>
  </div>
</div>
